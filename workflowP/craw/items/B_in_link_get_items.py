import logging
import json
import re
import time
import os
from selenium.webdriver.chrome.service import Service
from pathlib import Path
from multiprocessing import Pool, cpu_count, Manager
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from A_link_filter import to_list

# ================== ìƒìˆ˜ ==================
THIS_FILE = Path(__file__).resolve()
PROJ_ROOT = THIS_FILE.parents[2]
DATA_DIR = PROJ_ROOT / "craw" / "data"
DATA_DIR.mkdir(parents=True, exist_ok=True)
OUT_JSON = DATA_DIR / "quick_text_probe_parallel.json"

PAGELOAD_TIMEOUT = int(os.environ.get("PAGELOAD_TIMEOUT", "10"))
IMPLICIT_WAIT = int(os.environ.get("IMPLICIT_WAIT", "2"))
WAIT_TIMEOUT = int(os.environ.get("WAIT_TIMEOUT", "10"))
SAMPLE_N = int(os.environ.get("SAMPLE_N", "7000"))
WORKERS = int(os.environ.get("WORKERS", "4"))  # ë³‘ë ¬ ì‹¤í–‰ ê°œìˆ˜
CHECKPOINT_N = int(os.environ.get("CHECKPOINT_N", "10"))  # ì¤‘ê°„ ì €ì¥ ë‹¨ìœ„
# ë°°ì¹˜(ì²­í¬) í¬ê¸°: ê¸°ë³¸ 10 â†’ 10ê°œ ë‹¨ìœ„ë¡œ ë¶€ëª¨ê°€ ê²°ê³¼ ìˆ˜ì‹ /ì²´í¬í¬ì¸íŠ¸ ê°€ëŠ¥
BATCH_SIZE = int(os.environ.get("BATCH_SIZE", "10"))

LIST_SELECTORS = [
    "div.main_prodlist.main_prodlist_list > ul > li"
]

# ================== ë¡œê¹… ==================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s][%(processName)s] %(message)s",
    datefmt="%H:%M:%S",
)
log = logging.getLogger(__name__)

# ================== ìœ í‹¸ ==================
def clean_text(s: str) -> str:
    """í…ìŠ¤íŠ¸ ì •ì œ"""
    if not s:
        return ""
    s = re.sub(r"[ \t\r\f]+", " ", s)
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()

def find_product_items(driver):
    """ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ íƒìƒ‰ (ë¡œë“œ ëŒ€ê¸° í¬í•¨)"""
    for sel in LIST_SELECTORS:
        try:
            WebDriverWait(driver, WAIT_TIMEOUT).until(
                EC.presence_of_all_elements_located((By.CSS_SELECTOR, sel))
            )
            els = driver.find_elements(By.CSS_SELECTOR, sel)
            if els:
                return els, sel
        except Exception:
            pass
    return [], ""

# ================== ì›Œì»¤ í•¨ìˆ˜ ==================
def worker(args):
    """ë§í¬ ë¦¬ìŠ¤íŠ¸ í•œ ë¬¶ìŒì„ ë³‘ë ¬ë¡œ í¬ë¡¤ë§"""
    link_batch, start_index, total = args
    results = []

    # í¬ë¡¬ ì˜µì…˜ ì„¤ì •
    service = Service(log_path=os.devnull)
    options = Options()
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-software-rasterizer")
    options.add_argument("--window-size=1400,1000")
    options.add_argument("--headless=new")
    options.add_argument("--log-level=3")
    options.add_argument("--silent")
    options.add_argument("--disable-logging")
    options.add_argument("--disable-extensions")
    options.add_argument("--disable-notifications")
    options.add_argument("--disable-default-apps")
    options.add_argument("--disable-breakpad")
    options.add_argument("--no-default-browser-check")
    options.add_argument("--no-first-run")
    options.add_argument("--mute-audio")

    options.add_experimental_option("excludeSwitches", [
        "enable-logging",
        "enable-automation",
        "enable-blink-features=AutomationControlled"
    ])
    options.add_experimental_option("useAutomationExtension", False)

    driver = webdriver.Chrome(service=service, options=options)
    driver.set_page_load_timeout(PAGELOAD_TIMEOUT)
    driver.implicitly_wait(IMPLICIT_WAIT)

    # ì§„í–‰ë„ ì¶œë ¥ í­ ê³„ì‚° (ì˜ˆ: 1250 -> í­ 5 ì— ë§ì¶° ìš°ì¸¡ ì–¸ë”ìŠ¤ì½”ì–´ íŒ¨ë”©)
    width = max(5, len(str(total)))

    for idx, r in enumerate(link_batch, start=0):
        cur = start_index + idx
        cur_disp = f"{cur}{' ' * (width - len(str(cur)))}"
        prog_str = f"ì§„í–‰ë„ [{cur_disp}/ {total}]"
        link = r.get("link")
        path = [r.get(f"{i}ì°¨", "") for i in range(1, 5)]
        result = {"link": link, "path": path, "ok": False, "products": []}

        try:
            driver.get(link)
            time.sleep(2)

            # ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ íƒìƒ‰
            items, used_sel = find_product_items(driver)
            if not items:
                continue

            for item in items[:30]:  # ìµœëŒ€ 30ê°œ
                try:
                    # ================== ì´ë¯¸ì§€ ==================
                    img_el = item.find_element(
                        By.CSS_SELECTOR,
                        "div.prod_main_info > div.thumb_image > a.thumb_link > img"
                    )
                    image = img_el.get_attribute("data-original") or img_el.get_attribute("src")

                    # ================== ìƒí’ˆëª… ==================
                    prod_name = clean_text(
                        item.find_element(
                            By.CSS_SELECTOR,
                            "div.prod_main_info > div.prod_info > p > a"
                        ).text
                    )

                    # ================== ìŠ¤í™/íƒœê·¸ ==================
                    tags_css = ", ".join([
                        "div.prod_main_info div.prod_info div.spec-box[data-simple-description-open-area='Y'] div.spec_list",
                        "div.prod_main_info div.prod_info div.spec-box:not([style*='display:none']) div.spec_list",
                        "div.prod_info div.spec-box[data-simple-description-open-area='Y'] div.spec_list",
                        "div.prod_info div.spec-box:not([style*='display:none']) div.spec_list",
                    ])
                    tags_elem = item.find_elements(By.CSS_SELECTOR, tags_css)
                    tags = clean_text(tags_elem[0].text if tags_elem else "")

                    # ================== ê°€ê²© ==================
                    price_els = item.find_elements(
                        By.CSS_SELECTOR,
                        "div.prod_main_info > div.prod_pricelist > ul > li p.price_sect > a > strong"
                    )
                    price = clean_text(price_els[0].text if price_els else "")

                    # ================== ì €ì¥ ==================
                    result["products"].append({
                        "image": image,
                        "prod_name": prod_name,
                        "tags": tags,
                        "price": price
                    })

                except Exception as e:
                    log.debug("item parse error: %s", e, exc_info=True)
                    continue

            result.update({
                "ok": True,
                "list_selector": used_sel,
                "product_count": len(result["products"])
            })
            results.append(result)
            log.info(f"âœ… {len(result['products'])}ê°œ ì™„ë£Œ | {prog_str} - {path[1] if len(path) > 1 else path[0]}")

        except Exception as e:
            log.warning(f"âŒ {path[-1] if path[-1] else link} ì—ëŸ¬: {e}")

    driver.quit()
    return results

# ================== ë©”ì¸ ==================
def _read_existing_results(path: Path):
    if not path.exists():
        return []
    try:
        with path.open("r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return []

def _atomic_write_json(path: Path, data):
    tmp = path.with_suffix(path.suffix + ".tmp")
    with tmp.open("w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    tmp.replace(path)

def main():
    rows = to_list()
    if not rows:
        log.warning("í•„í„°ëœ ë§í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì¤‘ë³µ ì œê±°
    uniq, seen = [], set()
    for r in rows:
        lk = r.get("link", "")
        if lk and lk not in seen:
            uniq.append(r)
            seen.add(lk)

    # ğŸ”¹ ê¸°ì¡´ ê²°ê³¼ ë¡œë“œ ë° ì¬ì‹œì‘ ìŠ¤í‚µ êµ¬ì„±
    prev_results = _read_existing_results(OUT_JSON)
    prev_links = {r.get("link") for r in prev_results if isinstance(r, dict) and r.get("ok")}

    # ğŸ”¹ ì²˜ë¦¬ ê°œìˆ˜ ì œí•œ (deterministic)
    total = min(SAMPLE_N, len(uniq)) if SAMPLE_N > 0 else len(uniq)
    uniq = uniq[:total]

    # ğŸ”¹ ì¬ì‹œì‘ ìŠ¤í‚µ ì ìš©
    todo = [r for r in uniq if r.get("link") not in prev_links]
    skipped = len(uniq) - len(todo)
    log.info(f"ì´ {len(rows)}ê°œ ì¤‘ ìƒìœ„ {total}ê°œ ë§í¬ ë³‘ë ¬ ì ê²€ ì‹œì‘ (ì´ì „ ì™„ë£Œ {skipped}ê°œ ìŠ¤í‚µ)")

    # ğŸ”¹ ë³‘ë ¬ ì²˜ë¦¬ ë¶„í• 
    chunk_size = max(1, min(BATCH_SIZE, len(todo))) if todo else 1
    raw_chunks = [todo[i:i + chunk_size] for i in range(0, len(todo), chunk_size)]
    # ê° ì²­í¬ì˜ ì‹œì‘ ì¸ë±ìŠ¤(1-based)ì™€ ì´ ê°œìˆ˜ë¥¼ í•¨ê»˜ ì „ë‹¬í•˜ì—¬ ì „ì—­ ì§„í–‰ë„ë¥¼ ê³„ì‚°
    chunks = []
    start = 1
    for batch in raw_chunks:
        chunks.append((batch, start, total))
        start += len(batch)
    log.info(f"ê° í”„ë¡œì„¸ìŠ¤ë‹¹ {chunk_size}ê°œ ë§í¬ ì²˜ë¦¬ ì˜ˆì •")

    # ğŸ”¹ ë³‘ë ¬ ì‹¤í–‰
    manager = Manager()
    shared_results = manager.list()  # ë³‘ë ¬ ì•ˆì „ ìˆ˜ì§‘
    lock = manager.Lock()

    processed_total = 0
    last_checkpoint_at = 0

    def _maybe_checkpoint():
        nonlocal last_checkpoint_at
        current_total = len(prev_results) + len(shared_results)
        if CHECKPOINT_N > 0 and current_total - last_checkpoint_at >= CHECKPOINT_N:
            with lock:
                data = list(prev_results) + list(shared_results)
                _atomic_write_json(OUT_JSON, data)
                last_checkpoint_at = current_total
                log.info(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ({current_total}ê°œ) â†’ {OUT_JSON}")

    if todo:
        with Pool(WORKERS) as pool:
            for batch_results in pool.imap_unordered(worker, chunks):
                with lock:
                    for item in batch_results:
                        shared_results.append(item)
                processed_total += len(batch_results)
                _maybe_checkpoint()

    # ğŸ”¹ ìµœì¢… ì €ì¥ (ì´ì „ + ì‹ ê·œ)
    final_data = list(prev_results) + list(shared_results)
    _atomic_write_json(OUT_JSON, final_data)
    log.info(f"âœ… ë³‘ë ¬ í¬ë¡¤ë§ ì™„ë£Œ: ì‹ ê·œ {len(shared_results)}ê°œ, ëˆ„ì  {len(final_data)}ê°œ ì €ì¥ â†’ {OUT_JSON}")

"""ë‹¨ì¼ ì‹¤í–‰ ì—”íŠ¸ë¦¬"""
if __name__ == "__main__":
    main()
